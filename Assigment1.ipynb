{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97196a3e-919b-4fa5-9c19-6339a43c4f5f",
   "metadata": {},
   "source": [
    "# Ans1-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7408cf-616d-4a13-b365-18aa0a9c5132",
   "metadata": {},
   "source": [
    "Linear regression predict the contineuos outcomes while logistic regression predict the binary outcome for example prediction exam scores vs pass or fails status in a student datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82c4f2-f14f-412f-9898-64a5e79409ce",
   "metadata": {},
   "source": [
    "# Ans2-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124204d3-2e57-4d1d-bfdd-992ecb96b061",
   "metadata": {},
   "source": [
    "logistic regression uses the cross-entropy or log-log function optimized through gradient decent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e57d0c-9cfa-4a01-95d8-99590793fd6c",
   "metadata": {},
   "source": [
    "# Ans3-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e60244-ec3f-47a8-95b8-a1ee008bc457",
   "metadata": {},
   "source": [
    "Regularization in logistic regression add a penalty term to the cost function discouraging overly complex model and preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e5062a-9d05-4f62-b76a-b5a83bd5e8d5",
   "metadata": {},
   "source": [
    "# Ans4-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4274acd3-98f7-4e57-a9fa-1e5be3fd0963",
   "metadata": {},
   "source": [
    "ROC curve illustrates the trade-off between sensitivity and specificity helping assess the performance of logistic regression model by plotting its true positive rate against false positive rate at various threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca809a-924a-47b7-9672-9b0800bd20c1",
   "metadata": {},
   "source": [
    "# Ans5-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf116df5-31f6-4dfa-8560-7c53120febe5",
   "metadata": {},
   "source": [
    "common feature selection techniques for logistic regression include l1 regularization(lasso),reccursive feature elimination(rfe)and information gain these method enhance the model performance and select the most relevent features and reducing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915d3ed9-d1df-46ae-994b-aa25c2257964",
   "metadata": {},
   "source": [
    "# Ans6-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff6b02-e8da-4325-8cae-455363b0f564",
   "metadata": {},
   "source": [
    "handling imbalanced dataset in logistic regression can involves techniques such as oversampling the minarity class ,undersampling the majority class or using method like smote(synthetic minarity over sampling techniques) to balance class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3220f08f-3173-4d5b-86b2-aaabededdd93",
   "metadata": {},
   "source": [
    "# Ans7-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07427c8c-2f75-48c3-be56-18f8b240bdd2",
   "metadata": {},
   "source": [
    "multicolinearity in logistic regression can be addressed by removing highly correlated variables using dimensionality reduction techniques like pca or applying regularization method such as laso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072db97-55e7-4595-8088-5505c8f41ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
